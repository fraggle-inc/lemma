{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a lemmatizer with lemma\n",
    "In this notebook, you will see how to train a lemmatizer using lemma. It assumes you already have a CSV file of the \n",
    "format *pos*, *full_form*, *lemma*. The previous notebook, *01 prepare*, explains how to create such a file using data from Dansk Sprognævn and the Universal Dependency data.\n",
    "\n",
    "We initially create a train/test split and train on the training data only and then evaluate on the train and test set respectively. We then train again on the entire dataset and save the trained rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import random\n",
    "import pandas as pd\n",
    "from lemma import Lemmatizer\n",
    "logging.basicConfig(level=logging.DEBUG, format=\"%(levelname)s : %(message)s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPARED_FILE = \"./data/prepared.csv\"\n",
    "TRAINED_RULES_FILE = \"./data/rules.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    df = pd.read_csv(filename, usecols=[0, 1, 2], keep_default_na=False)\n",
    "    X = [(word_class, full_form) for _, (word_class, full_form, _) in df.iterrows()]\n",
    "    y = [lemma for _, (_word_class, _full_form, lemma,) in df.iterrows()]\n",
    "    return X, y\n",
    "\n",
    "def split_data(X, y):\n",
    "    mask = [False] * len(y)\n",
    "    test_indices = random.sample(range(len(y)), len(y) // 500)\n",
    "    for index in test_indices:\n",
    "        mask[index] = True\n",
    "\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for index, test in enumerate(mask):\n",
    "        if test:\n",
    "            X_test += [X[index]]\n",
    "            y_test += [y[index]]\n",
    "        else:\n",
    "            X_train += [X[index]]\n",
    "            y_train += [y[index]]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def print_examples(lemmatizer):\n",
    "    examples = [[\"VERB\", \"drak\"], [\"NOUN\", \"kattene\"], [\"NOUN\", \"ukrudtet\"], [\"NOUN\", \"slaraffenlandet\"],\n",
    "                [\"NOUN\", \"alen\"], [\"NOUN\", \"skaber\"], [\"NOUN\", \"venskaber\"], [\"NOUN\", \"tilbageførelser\"],\n",
    "                [\"NOUN\", \"aftenbønnerne\"], [\"NOUN\", \"altankassepassere\"]]\n",
    "    for word_class, full_form in examples:\n",
    "        lemma = lemmatizer.lemmatize(word_class, full_form)\n",
    "        print(\"(%s, %s) -> %s\" % (word_class, full_form, lemma))\n",
    "\n",
    "def calculate_accuracy(lemmatizer, X, y):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    ambiguous = 0\n",
    "\n",
    "    for index in range(len(y)):\n",
    "        word_class, full_form = X[index]\n",
    "        target = y[index]\n",
    "        predicted = lemmatizer.lemmatize(word_class, full_form)\n",
    "        total += 1\n",
    "        if len(predicted) > 1:\n",
    "            ambiguous += 1\n",
    "        elif predicted[0] == target:\n",
    "            correct += 1\n",
    "        else:            \n",
    "            #print(\"(%s, %s) -> %s (expected: %s)\" % (word_class, full_form, predicted, target))\n",
    "            pass\n",
    "\n",
    "    print(\"correct:\", correct)\n",
    "    print(\"ambiguous:\", ambiguous)\n",
    "    print(\"total:\", total)\n",
    "    print(\"accuracy:\", correct/total)\n",
    "    print(\"ambiguous%:\", ambiguous/total)\n",
    "    print(\"ambiguous + accuracy:\", (ambiguous+correct)/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data(PREPARED_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "X_train, y_train, X_test, y_test = split_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete set:     402189\n",
      "Train set:        401385\n",
      "Test set:            804\n"
     ]
    }
   ],
   "source": [
    "print(f\"Complete set: {len(X):10}\")\n",
    "print(f\"Train set:    {len(X_train):10}\")\n",
    "print(f\"Test set:     {len(X_test):10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train temmatizer - training set only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : epoch #1: 46905 rules (46905 new) in 1.87s\n",
      "DEBUG : epoch #2: 62807 rules (15902 new) in 1.75s\n",
      "DEBUG : epoch #3: 66231 rules (3424 new) in 1.65s\n",
      "DEBUG : epoch #4: 67281 rules (1050 new) in 1.73s\n",
      "DEBUG : epoch #5: 67680 rules (399 new) in 1.59s\n",
      "DEBUG : epoch #6: 67784 rules (104 new) in 1.80s\n",
      "DEBUG : epoch #7: 67808 rules (24 new) in 1.96s\n",
      "DEBUG : epoch #8: 67824 rules (16 new) in 1.73s\n",
      "DEBUG : epoch #9: 67824 rules (0 new) in 2.02s\n",
      "DEBUG : training complete: 67824 rules in 16.18s\n",
      "DEBUG : rules before pruning: 67824\n",
      "DEBUG : used rules: 59962\n",
      "DEBUG : rules after pruning: 59962 (7862 removed)\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = Lemmatizer()\n",
    "lemmatizer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 394911\n",
      "ambiguous: 6474\n",
      "total: 401385\n",
      "accuracy: 0.9838708471915991\n",
      "ambiguous%: 0.016129152808400913\n",
      "ambiguous + accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "calculate_accuracy(lemmatizer, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 745\n",
      "ambiguous: 9\n",
      "total: 804\n",
      "accuracy: 0.9266169154228856\n",
      "ambiguous%: 0.011194029850746268\n",
      "ambiguous + accuracy: 0.9378109452736318\n"
     ]
    }
   ],
   "source": [
    "calculate_accuracy(lemmatizer, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(VERB, drak) -> ['drikke']\n",
      "(NOUN, kattene) -> ['kat']\n",
      "(NOUN, ukrudtet) -> ['ukrudt']\n",
      "(NOUN, slaraffenlandet) -> ['slaraffenland']\n",
      "(NOUN, alen) -> ['al', 'ale', 'alen']\n",
      "(NOUN, skaber) -> ['skaber']\n",
      "(NOUN, venskaber) -> ['venskab']\n",
      "(NOUN, tilbageførelser) -> ['tilbageførelse']\n",
      "(NOUN, aftenbønnerne) -> ['aftenbøn']\n",
      "(NOUN, altankassepassere) -> ['altankassepasser']\n"
     ]
    }
   ],
   "source": [
    "print_examples(lemmatizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train temmatizer - full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : epoch #1: 46954 rules (46954 new) in 1.93s\n",
      "DEBUG : epoch #2: 62892 rules (15938 new) in 1.92s\n",
      "DEBUG : epoch #3: 66324 rules (3432 new) in 1.74s\n",
      "DEBUG : epoch #4: 67372 rules (1048 new) in 2.03s\n",
      "DEBUG : epoch #5: 67771 rules (399 new) in 2.12s\n",
      "DEBUG : epoch #6: 67875 rules (104 new) in 1.95s\n",
      "DEBUG : epoch #7: 67899 rules (24 new) in 1.69s\n",
      "DEBUG : epoch #8: 67915 rules (16 new) in 1.70s\n",
      "DEBUG : epoch #9: 67915 rules (0 new) in 1.67s\n",
      "DEBUG : training complete: 67915 rules in 16.85s\n",
      "DEBUG : rules before pruning: 67915\n",
      "DEBUG : used rules: 60045\n",
      "DEBUG : rules after pruning: 60045 (7870 removed)\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = Lemmatizer()\n",
    "lemmatizer.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 395697\n",
      "ambiguous: 6492\n",
      "total: 402189\n",
      "accuracy: 0.9838583352602881\n",
      "ambiguous%: 0.016141664739711927\n",
      "ambiguous + accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "calculate_accuracy(lemmatizer, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Learned Rules\n",
    "We now save the learend rules to a Python file which can be copied to the lemmatizer source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _to_dict(lemmatizer):\n",
    "    \"\"\"Convert the internal defaultdict to a standard dict.\"\"\"\n",
    "    temp = {}\n",
    "    for pos, rules_ in lemmatizer.rules.items():\n",
    "        if pos not in temp:\n",
    "            temp[pos] = {}\n",
    "\n",
    "        for full_form_suffix, lemma_suffixes_ in rules_.items():\n",
    "            temp[pos][full_form_suffix] = lemma_suffixes_\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1801484"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(TRAINED_RULES_FILE, 'w').write(\"rules = \" + str(_to_dict(lemmatizer)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
